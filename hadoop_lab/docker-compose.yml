version: "3"

services:
         
  namenode:
    build: .
    container_name: namenode
    hostname: namenode-master
    ports:
      - "9870:9870"
      - "50030:50030" 
    volumes:
      - ./data:/data
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_MAPRED_HOME=/opt/hadoop
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    command: bash -c "
      hdfs namenode -format -force &&
      hdfs namenode"
    logging:
      driver: json-file
      options:
        max-size: "50m"

  yarnmaster:
    build: .
    container_name: yarnmaster
    hostname: yarnmaster
    ports:
      - "8088:8088"
      - "19888:19888"
    depends_on:
      - namenode
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_MAPRED_HOME=/opt/hadoop
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    command: yarn resourcemanager

  datanode:
    build: .
    container_name: datanode
    hostname: datanode
    depends_on:
      - namenode
      - yarnmaster
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_MAPRED_HOME=/opt/hadoop
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    command: bash -c "
      hdfs --daemon start datanode &&
      yarn nodemanager"

  hadoopclient:
    build: .
    container_name: hadoop
    hostname: hadoop-client
    depends_on:
      - namenode
      - yarnmaster
      - datanode
    volumes:
      - ./data:/data
    command: /bin/bash



